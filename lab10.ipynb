{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'mps' if torch.backends.mps.is_available() else device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacingRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(SpacingRNN, self).__init__()\n",
    "        \n",
    "        # (batch_size, max_length) -> (batch_size, max_length, embedding_size)\n",
    "        self.embedding = \n",
    "        # (batch_size, max_length, embedding_size) -> (batch_size, max_length, hidden_size*2)\n",
    "        self.bi_lstm = \n",
    "        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_labels)\n",
    "        self.linear = \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        eumjeol_inputs = self.embedding(inputs)\n",
    "        hidden_outputs, _ = self.bi_lstm(eumjeol_inputs)\n",
    "        hypothesis = self.linear(hidden_outputs)\n",
    "        \n",
    "        return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datas(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n",
    "        lines = inFile.readlines()\n",
    "    datas = []\n",
    "    # sample data: 그 사 람 을 아 직 도 사 랑 하 나 요 ?\\t B B I I B I I B I I I I I \n",
    "    for line in lines:\n",
    "        # ['그 사 람 을 아 직 도 사 랑 하 나 요 ?', 'B B I I B I I B I I I I I']\n",
    "        # ['그', '사', '람', '을', '아', '직', '도', '사', '랑', '하', '나', '요', '?'],\n",
    "        # ['B', 'B', 'I', 'I', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'I']\n",
    "        datas.append((eumjeol_list, label_list))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocab_data(eumjeol_vocab_data_path):\n",
    "    label2idx, idx2label = {\"<PAD>\":0, \"B\":1, \"I\":2}, {0:\"<PAD>\", 1:\"B\", 2:\"I\"}\n",
    "    eumjeol2idx, idx2eumjeol = {}, {}\n",
    "\n",
    "    with open(eumjeol_vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n",
    "        lines = inFile.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        eumjeol = line.strip()\n",
    "        eumjeol2idx[eumjeol] = len(eumjeol2idx)\n",
    "        idx2eumjeol[eumjeol2idx[eumjeol]] = eumjeol\n",
    "\n",
    "    return eumjeol2idx, idx2eumjeol, label2idx, idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config, is_train=True):\n",
    "    datas = read_datas(config[\"input_data\"])\n",
    "    eumjeol2idx, idx2eumjeol, label2idx, idx2label = read_vocab_data(config[\"eumjeol_vocab\"])\n",
    "    \n",
    "    eumjeol_features, eumjeol_feature_lengths, label_features = [], [], []\n",
    "    \n",
    "    for eumjeol_sequence, label_sequence in datas:\n",
    "        eumjeol_feature = [eumjeol2idx[eumjeol] for eumjeol in eumjeol_sequence]\n",
    "        label_feature = [label2idx[label] for label in label_sequence]\n",
    "        \n",
    "        eumjeol_feature_length = len(eumjeol_feature)\n",
    "        \n",
    "        eumjeol_feature +=  \n",
    "        label_feature += \n",
    "        \n",
    "        eumjeol_features.append(eumjeol_feature)\n",
    "        eumjeol_feature_lengths.append(eumjeol_feature_length)\n",
    "        label_features.append(label_feature)\n",
    "        \n",
    "    if is_train:\n",
    "        return torch.tensor(eumjeol_features, dtype=torch.long), \\\n",
    "               torch.tensor(eumjeol_feature_lengths, dtype=torch.long), \\\n",
    "               torch.tensor(label_features, dtype=torch.long)\n",
    "    else:\n",
    "        return torch.tensor(eumjeol_features, dtype=torch.long), \\\n",
    "           torch.tensor(eumjeol_feature_lengths, dtype=torch.long), \\\n",
    "           torch.tensor(label_features, dtype=torch.long), idx2eumjeol, idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    model = SpacingRNN(config).to(device)\n",
    "    eumjeol_features, eumjeol_feature_lengths, label_features = load_dataset(config)\n",
    "    train_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n",
    "    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        model.train()\n",
    "        costs = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n",
    "            \n",
    "            hypothesis = \n",
    "            cost = \n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            # batch 단위 cost 값 저장\n",
    "            costs.append(cost.data.item())\n",
    "            \n",
    "            # 10 step 마다 loss 값 출력\n",
    "            if (step+1) % 10 == 0:\n",
    "                print(\"Epoch : {0:d}, Step : {1:d}, Cost : {2:.6f}\".format(epoch + 1, step+1, cost.data.item()))\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"epoch_{0:d}.pt\".format(epoch + 1)))\n",
    "\n",
    "        # epoch 별로 평균 loss 값 출력\n",
    "        print(\"Epoch : {0:d}, Average Cost : {1:.6f}\".format(epoch + 1, np.mean(costs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence(inputs, predicts, labels, idx2eumjeol, idx2label):\n",
    "\n",
    "    predict_sentence, correct_sentence = \"\", \"\"\n",
    "\n",
    "    for index in range(len(inputs)):\n",
    "        eumjeol = idx2eumjeol[inputs[index]]\n",
    "        correct_label = idx2label[labels[index]]\n",
    "        predict_label = idx2label[predicts[index]]\n",
    "\n",
    "        if (index == 0):\n",
    "            predict_sentence += eumjeol\n",
    "            correct_sentence += eumjeol\n",
    "            continue\n",
    "\n",
    "        if (predict_label == \"B\"):\n",
    "            predict_sentence += \" \"\n",
    "        predict_sentence += eumjeol\n",
    "\n",
    "        if (correct_label == \"B\"):\n",
    "            correct_sentence += \" \"\n",
    "        correct_sentence += eumjeol\n",
    "\n",
    "    return predict_sentence, correct_sentence\n",
    "\n",
    "def tensor2list(input_tensor):\n",
    "    return input_tensor.cpu().detach().numpy().tolist()\n",
    "\n",
    "def test(config):\n",
    "    eumjeol_features, eumjeol_feature_lengths, label_features, idx2eumjeol, idx2label = load_dataset(config, False)\n",
    "\n",
    "    test_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n",
    "    test_dataloader = DataLoader(test_features, shuffle=False, batch_size=1)\n",
    "\n",
    "    model = SpacingRNN(config).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(config[\"output_dir_path\"], config[\"model_name\"])))\n",
    "\n",
    "    total_hypothesis, total_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n",
    "\n",
    "        hypothesis = model(inputs)\n",
    "\n",
    "        hypothesis = torch.argmax(hypothesis, dim=-1)\n",
    "\n",
    "        input_length = tensor2list(input_lengths[0])\n",
    "        input = tensor2list(inputs[0])[:input_length]\n",
    "        label = tensor2list(labels[0])[:input_length]\n",
    "        hypothesis = tensor2list(hypothesis[0])[:input_length]\n",
    "\n",
    "        total_hypothesis += hypothesis\n",
    "        total_labels += label\n",
    "\n",
    "        if (step < 10):\n",
    "            predict_sentence, correct_sentence = make_sentence(input, hypothesis, label, idx2eumjeol, idx2label)\n",
    "            print(\"정답 : \" + correct_sentence)\n",
    "            print(\"출력 : \" + predict_sentence)\n",
    "            print()\n",
    "\n",
    "    print(\"Accuracy : {}\".format(accuracy_score(total_labels, total_hypothesis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Step : 10, Cost : 0.790247\n",
      "Epoch : 1, Step : 20, Cost : 0.053088\n",
      "Epoch : 1, Step : 30, Cost : 0.042955\n",
      "Epoch : 1, Step : 40, Cost : 0.030374\n",
      "Epoch : 1, Step : 50, Cost : 0.027951\n",
      "Epoch : 1, Step : 60, Cost : 0.022417\n",
      "Epoch : 1, Step : 70, Cost : 0.023687\n",
      "Epoch : 1, Average Cost : 0.194883\n",
      "Epoch : 2, Step : 10, Cost : 0.020986\n",
      "Epoch : 2, Step : 20, Cost : 0.021146\n",
      "Epoch : 2, Step : 30, Cost : 0.023556\n",
      "Epoch : 2, Step : 40, Cost : 0.030308\n",
      "Epoch : 2, Step : 50, Cost : 0.019190\n",
      "Epoch : 2, Step : 60, Cost : 0.021448\n",
      "Epoch : 2, Step : 70, Cost : 0.021140\n",
      "Epoch : 2, Average Cost : 0.020738\n",
      "Epoch : 3, Step : 10, Cost : 0.020440\n",
      "Epoch : 3, Step : 20, Cost : 0.019457\n",
      "Epoch : 3, Step : 30, Cost : 0.018071\n",
      "Epoch : 3, Step : 40, Cost : 0.017924\n",
      "Epoch : 3, Step : 50, Cost : 0.016297\n",
      "Epoch : 3, Step : 60, Cost : 0.014533\n",
      "Epoch : 3, Step : 70, Cost : 0.017216\n",
      "Epoch : 3, Average Cost : 0.017471\n",
      "Epoch : 4, Step : 10, Cost : 0.013262\n",
      "Epoch : 4, Step : 20, Cost : 0.013349\n",
      "Epoch : 4, Step : 30, Cost : 0.015775\n",
      "Epoch : 4, Step : 40, Cost : 0.015360\n",
      "Epoch : 4, Step : 50, Cost : 0.013322\n",
      "Epoch : 4, Step : 60, Cost : 0.011164\n",
      "Epoch : 4, Step : 70, Cost : 0.014490\n",
      "Epoch : 4, Average Cost : 0.014218\n",
      "Epoch : 5, Step : 10, Cost : 0.011144\n",
      "Epoch : 5, Step : 20, Cost : 0.011954\n",
      "Epoch : 5, Step : 30, Cost : 0.010749\n",
      "Epoch : 5, Step : 40, Cost : 0.010202\n",
      "Epoch : 5, Step : 50, Cost : 0.009664\n",
      "Epoch : 5, Step : 60, Cost : 0.012103\n",
      "Epoch : 5, Step : 70, Cost : 0.010253\n",
      "Epoch : 5, Average Cost : 0.011239\n"
     ]
    }
   ],
   "source": [
    "if(__name__==\"__main__\"):\n",
    "    root_dir = \".\"\n",
    "    output_dir = os.path.join(root_dir, \"output\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    config = {\"mode\": \"train\",\n",
    "              \"model_name\":\"epoch_{0:d}.pt\".format(5),\n",
    "              \"input_data\":os.path.join(root_dir, \"train-2.txt\"),\n",
    "              \"output_dir_path\":output_dir,\n",
    "              \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n",
    "              \"label_vocab\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
    "              \"eumjeol_vocab_size\": 2458,\n",
    "              \"embedding_size\": 100,\n",
    "              \"hidden_size\": 100,\n",
    "              \"max_length\": 920,\n",
    "              \"number_of_labels\": 3,\n",
    "              \"epoch\":5,\n",
    "              \"batch_size\":64,\n",
    "              \"dropout\":0.3\n",
    "              }\n",
    "\n",
    "    if(config[\"mode\"] == \"train\"):\n",
    "        train(config)\n",
    "    else:\n",
    "        test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 : 부인이 정성들여 키운 진이 독살되었다는 것은 연박사에게도 매우 가슴아픈 일일 것이다.\n",
      "출력 : 부인이 정성들여키운진이 독살되었다는 것은 연박사에게도 매우가 슴아픈일일 것이다.\n",
      "\n",
      "정답 : 이같은 그의 가난은 어려서만이 아니라 자란 뒤에도 늙을 때까지 줄기차게 계속되었다.\n",
      "출력 : 이 같은 그의 가난은 어려서만이 아니라자란 뒤에도 늙을 때까지줄기차게 계속되었다.\n",
      "\n",
      "정답 : 어느 물리학자의 머리 속.\n",
      "출력 : 어느 물리학자의 머리속.\n",
      "\n",
      "정답 : 말씨며 움직임이 세련되어 있었다.\n",
      "출력 : 말 씨며 움직임이 세련 되어 있었다.\n",
      "\n",
      "정답 : \"워싱턴과 뉴욕에서 차출한 인원까지 모두 12 명이네.\"\n",
      "출력 : \"워싱턴과 뉴욕에서 차출한 인원까지 모두 12명이네.\"\n",
      "\n",
      "정답 : \"그 사람을 아직도 사랑하나요?\"\n",
      "출력 : \" 그사람을 아직도 사랑하나요?\"\n",
      "\n",
      "정답 : \"나한테 걸린 건 행복한 거예요. 나를 훔치려는 사내들이 많아요. 무슨 말인지 알아요?\"\n",
      "출력 : \"나한테 걸린건행복한 거예요. 나를 훔치려는 사내들이 많아요. 무슨 말인지 알아요?\"\n",
      "\n",
      "정답 : 김광민은 집에 돌아와 있었으나 그 얘기를 바로 주남 마을과 녹동 마을에서 일어난 일이었기 때문에 자세히 들을 수 있었다.\n",
      "출력 : 김 광민은 집에 돌아와 있었으나 그 얘기를 바로 주남마을 과 녹동마을에서 일어난 일이었기 때문에 자세히들을 수 있었다.\n",
      "\n",
      "정답 : 미리 이야기해 두는 게 좋을 것 같아.\"\n",
      "출력 : 미리이야기해 두는게 좋을 것 같아.\"\n",
      "\n",
      "정답 : \"부인의 입장에서 남편의 자살을 얘기하는 말투로는 너무 냉정하다는 생각 안 드세요?\"\n",
      "출력 : \"부인의 입장에서 남편의 자살을 얘기하는 말투로는 너무냉정하다는 생각안드세요?\"\n",
      "\n",
      "Accuracy : 0.8894696490288663\n"
     ]
    }
   ],
   "source": [
    "if(__name__==\"__main__\"):\n",
    "    root_dir = \".\"\n",
    "    output_dir = os.path.join(root_dir, \"output\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    config = {\"mode\": \"test\",\n",
    "              \"model_name\":\"epoch_{0:d}.pt\".format(5),\n",
    "              \"input_data\":os.path.join(root_dir, \"train-2.txt\"),\n",
    "              \"output_dir_path\":output_dir,\n",
    "              \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n",
    "              \"label_vocab\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
    "              \"eumjeol_vocab_size\": 2458,\n",
    "              \"embedding_size\": 100,\n",
    "              \"hidden_size\": 100,\n",
    "              \"max_length\": 920,\n",
    "              \"number_of_labels\": 3,\n",
    "              \"epoch\":5,\n",
    "              \"batch_size\":64,\n",
    "              \"dropout\":0.3\n",
    "              }\n",
    "\n",
    "    if(config[\"mode\"] == \"train\"):\n",
    "        train(config)\n",
    "    else:\n",
    "        test(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ossp1-2401",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
